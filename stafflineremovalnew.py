# -*- coding: utf-8 -*-
"""staffLineRemovalNew.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_k_9jMebSuBtyreMzRqr7Xdb_bYEAlx6
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dropout, BatchNormalization, Input

datapath = "/content/drive/MyDrive/StaffLineRemovalProject/Dataset"

trainPaths = []
trainCleanedPaths = []

for foldername in os.listdir(datapath):
    imgFolder = f"{foldername}/image"
    imgFolderPath = os.path.join(datapath, imgFolder)
    for imgName in os.listdir(imgFolderPath):
        trainPaths.append(f"{datapath}/{foldername}/image/{imgName}")
        trainCleanedPaths.append(f"{datapath}/{foldername}/symbol/{imgName}")

len(trainPaths), len(trainCleanedPaths)

trainPaths[0], trainCleanedPaths[0]

# Next step is to define function to process images and then store this images in list.
# As there is not as many data, we do not need to work in batches.

# prepare function
def process_image(path):
    img = cv2.imread(path)
    img = np.asarray(img, dtype="float32")
    img = cv2.resize(img, (540, 420))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = img/255.0
    img = np.reshape(img, (420, 540, 1))

    return img

# Reshape images and put them into list.

# preprocess images
train = []
train_cleaned = []
test = []

import time
s = time.time()

for f in trainPaths:
    train.append(process_image(f))

for f in trainCleanedPaths:
    train_cleaned.append(process_image(f))

for f in trainPaths:
    test.append(process_image(f))

e = time.time()
print(e-s)

trainPaths, trainCleanedPaths = None, None

np.array(train).shape

# Visualize

plt.figure(figsize=(15,25))

for i in range(0, 8, 2):
    plt.subplot(4, 2, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(train[i][:,:,0], cmap='gray')
    plt.title('Noise image')

    plt.subplot(4,2,i+2)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(train_cleaned[i][:,:,0], cmap='gray')
    plt.title('Denoised image')

plt.show()

# In this step we convert lists to numpy arrays and split dataset into train and validation in ration 85% train, 15% test.

# convert list to numpy array
X_train = np.asarray(train)
Y_train = np.asarray(train_cleaned)
X_test = np.asarray(test)

X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.15)
X_train.shape, X_val.shape, Y_train.shape, Y_val.shape

train, train_cleaned, test = None, None, None

# Define the model

def model():
    input_layer = Input(shape=(420, 540, 1))

    # encoding
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)
    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = BatchNormalization()(x)

    x = MaxPooling2D((2, 2), padding='same')(x)

    x = Dropout(0.5)(x)

    # decoding
    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = BatchNormalization()(x)

    x = UpSampling2D((2, 2))(x)

    output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)
    model = Model(inputs=[input_layer], outputs=[output_layer])
    model.compile(optimizer='adam' , loss='mean_squared_error', metrics=['mae'])

    return model

model = model()
model.summary()

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

import time

# Train Model

callback = EarlyStopping(monitor='loss', patience=30)

start = time.time()

with tf.device('/device:GPU:0'):
    history = model.fit(
        X_train,
        Y_train,
        validation_data = (X_val, Y_val),
        epochs=100,
        batch_size=12,
        callbacks=[callback])

end = time.time()

print(end-start)

X_train, X_val, Y_train, Y_val = None, None, None, None

# Plot error evolution on epochs

# Check how loss & mae went down
epoch_loss = history.history['loss']
epoch_val_loss = history.history['val_loss']
epoch_mae = history.history['mae']
epoch_val_mae = history.history['val_mae']

plt.figure(figsize=(20,6))
plt.subplot(1,2,1)
plt.plot(range(0,len(epoch_loss)), epoch_loss, 'b-', linewidth=2, label='Train Loss')
plt.plot(range(0,len(epoch_val_loss)), epoch_val_loss, 'r-', linewidth=2, label='Val Loss')
plt.title('Evolution of loss on train & validation datasets over epochs')
plt.legend(loc='best')

plt.subplot(1,2,2)
plt.plot(range(0,len(epoch_mae)), epoch_mae, 'b-', linewidth=2, label='Train MAE')
plt.plot(range(0,len(epoch_val_mae)), epoch_val_mae, 'r-', linewidth=2,label='Val MAE')
plt.title('Evolution of MAE on train & validation datasets over epochs')
plt.legend(loc='best')

plt.show()

! pip install -q pyyaml h5py  # Required to save models in HDF5 format

model.save('cvcMuscimaKerasModel.h5')

# predict/clean test images
Y_test = model.predict(X_test, batch_size=1)

plt.figure(figsize=(15,25))
for i in range(0,8,2):
    plt.subplot(4,2,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(X_test[i][:,:,0], cmap='gray')
    plt.title('Noisy image')

    plt.subplot(4,2,i+2)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(Y_test[i][:,:,0], cmap='gray')
    plt.title('Denoised by autoencoder')

plt.show()